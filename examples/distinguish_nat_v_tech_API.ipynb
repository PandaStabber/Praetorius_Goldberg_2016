{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \n",
    "Note: python3. Please install requirements using requirments.txt in main directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import fnmatch\n",
    "import os.path\n",
    "import pandas as pd\n",
    "# import API one directory above\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"),os.path.pardir)))\n",
    "from distinguish_nat_vs_tech import distinguish_nat_vs_tech\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Directory structure\n",
    "Note: we generically define directory so it will work on any OS: mac/pc/linux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATABASES_BASEPATH = os.path.join(os.path.dirname(\"__file__\"))\n",
    "NATURAL_TRAINING_DATABASE_NAME_ = 'natural_training_data.csv'\n",
    "TECHNICAL_TRAINING_DATABASE_NAME_ = 'technical_training_data.csv'\n",
    "IMPORT_TRAINING_DATABASE_PATH = os.path.join(DATABASES_BASEPATH,'training_data')\n",
    "IMPORT_TESTING_DATABASE_PATH = os.path.join(DATABASES_BASEPATH,'test_data')\n",
    "OUTPUT_DATA_SUMMARY_PATH = os.path.join(os.path.dirname(\"__file__\"), 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import training files, combine, and concatenate into dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'training_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a2fe1ea7ce47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMPORT_TRAINING_DATABASE_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# find all csv's in directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtraining_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_data'"
     ]
    }
   ],
   "source": [
    "os.chdir(IMPORT_TRAINING_DATABASE_PATH)\n",
    "\n",
    "# find all csv's in directory\n",
    "training_files = glob.glob('*.csv')\n",
    "\n",
    "# iterate through files and assign classification id\n",
    "for file in training_files:\n",
    "    if fnmatch.fnmatchcase(file, TECHNICAL_TRAINING_DATABASE_NAME_):\n",
    "        technical_training_database = pd.DataFrame.from_csv(\n",
    "            os.path.join(file),header=0, index_col=None)\n",
    "        \n",
    "        # assign classification id\n",
    "        technical_training_database['Classification'] = 0\n",
    "        \n",
    "    elif fnmatch.fnmatchcase(file, NATURAL_TRAINING_DATABASE_NAME_):\n",
    "        natural_training_database = pd.DataFrame.from_csv(\n",
    "            os.path.join(file), header=0, index_col=None)\n",
    "        \n",
    "        # assign classification id\n",
    "        natural_training_database['Classification'] = 1\n",
    "\n",
    "# concatenate all the data into a single file\n",
    "training_data = pd.concat([natural_training_database, technical_training_database])\n",
    "\n",
    "# remoove all the na values (other filtering done later)\n",
    "training_data = training_data.dropna()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417\n"
     ]
    }
   ],
   "source": [
    "ISOTOPE_LIST_ = ['107Ag', '109Ag', '139La', '140Ce', '141Pr', '143Nd',\n",
    "                 '146Nd', '147Sm', '149Sm', '153Eu', '157Gd', '159Tb',\n",
    "                 '182W', '206Pb', '208Pb', '232Th', '238U', '25Mg',\n",
    "                 '55Mn', '59Co', '60Ni', '65Cu', '66Zn', '88Sr',\n",
    "                 '90Zr', '93Nb', '95Mo']\n",
    "\n",
    "# initialize class\n",
    "nat_v_tech = distinguish_nat_vs_tech()\n",
    "\n",
    "# initialize all isotopes\n",
    "nat_v_tech.isotope_list = ISOTOPE_LIST_\n",
    "\n",
    "# filter negative data\n",
    "nat_v_tech.filter_negative(training_data = training_data)\n",
    "\n",
    "# apply detection threshold\n",
    "nat_v_tech.apply_detection_threshold(training_data = nat_v_tech.training_data,\n",
    "                                     threshold_value= 5)\n",
    "\n",
    "# split target data from training data \n",
    "nat_v_tech.split_target_from_training_data(training_data=nat_v_tech.training_data)\n",
    "\n",
    "# prepare data for ML\n",
    "nat_v_tech.prepare_data_for_ML(training_data = nat_v_tech.training_data,\n",
    "                               target_data=nat_v_tech.target_data)\n",
    "\n",
    "# initialize gbc to determine max estimators with least overfitting\n",
    "GBC_INIT_PARAMS = {'loss': 'deviance', 'learning_rate': 0.1,\n",
    "                   'min_samples_leaf': 100, 'n_estimators': 1000,\n",
    "                   'max_depth': 5, 'random_state': None, 'max_features': 'sqrt'}\n",
    "\n",
    "nat_v_tech.find_min_boosting_stages(gbc_init_params=GBC_INIT_PARAMS)\n",
    "\n",
    "print (nat_v_tech.optimum_boosting_stages)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ISOTOPE_LIST_ = ['107Ag', '109Ag', '139La', '140Ce', '141Pr', '143Nd',\n",
    "                 '146Nd', '147Sm', '149Sm', '153Eu', '157Gd', '159Tb',\n",
    "                 '182W', '206Pb', '208Pb', '232Th', '238U', '25Mg',\n",
    "                 '55Mn', '59Co', '60Ni', '65Cu', '66Zn', '88Sr',\n",
    "                 '90Zr', '93Nb', '95Mo']\n",
    "\n",
    "CRITICAL_ISOTOPE_LIST_ = ['140Ce', '139La',\n",
    "                          '88Sr']\n",
    "\n",
    "GBC_GRID_SEARCH_PARAMS = {'loss': ['exponential', 'deviance'],\n",
    "                          'learning_rate': [0.01, 0.1],\n",
    "                          'min_samples_leaf': [50, 100],\n",
    "                          'random_state': [None],\n",
    "                          'max_features': ['sqrt', 'log2'],\n",
    "                          'max_depth': [5]}  # note n_estimators automatically set\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
