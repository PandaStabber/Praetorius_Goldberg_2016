{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports \n",
    "Note: python3. Please install requirements using requirments.txt in main directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import glob\n",
    "import fnmatch\n",
    "import os.path\n",
    "import pandas as pd\n",
    "# import API one directory above\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(\"__file__\"),os.path.pardir)))\n",
    "from distinguish_nat_vs_tech import distinguish_nat_vs_tech\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Directory structure\n",
    "Note: we generically define directory so it will work on any OS: mac/pc/linux.\n",
    "Note: drop the \"\" around \"__file__\" when in a regular python file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tron/Praetorius_Goldberg_2016\n",
      "/Users/tron/Praetorius_Goldberg_2016/examples/databases\n",
      "/Users/tron/Praetorius_Goldberg_2016/examples/databases/training_data\n",
      "/Users/tron/Praetorius_Goldberg_2016/examples/output\n"
     ]
    }
   ],
   "source": [
    "PARENT_PATH = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"),os.path.pardir))\n",
    "DATABASES_BASEPATH = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"),'databases'))\n",
    "IMPORT_TRAINING_DATABASE_PATH = os.path.abspath(\n",
    "    os.path.join(DATABASES_BASEPATH, 'training_data'))\n",
    "IMPORT_TESTING_DATABASE_PATH = os.path.abspath(\n",
    "    os.path.join(DATABASES_BASEPATH,'test_data'))\n",
    "OUTPUT_DATA_SUMMARY_PATH = os.path.abspath(\n",
    "    os.path.join(os.path.dirname(\"__file__\"), 'output'))\n",
    "\n",
    "\n",
    "# print the paths, just to make sure things make sense\n",
    "print(PARENT_PATH)\n",
    "print(DATABASES_BASEPATH)\n",
    "print(IMPORT_TRAINING_DATABASE_PATH)\n",
    "print (OUTPUT_DATA_SUMMARY_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training files\n",
    "Import training files, combine, and concatenate into dataframes. \n",
    "Note: if you re-run the notebook without resetting the kernal, you'll get an error. Restart the notebook kernal and it will work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['natural_training_data.csv', 'technical_training_data.csv']\n"
     ]
    }
   ],
   "source": [
    "# set the natural and technical database training file names\n",
    "NATURAL_TRAINING_DATABASE_NAME_ = 'natural_training_data.csv'\n",
    "TECHNICAL_TRAINING_DATABASE_NAME_ = 'technical_training_data.csv'\n",
    "\n",
    "# change the directory to the import training data path\n",
    "os.chdir(IMPORT_TRAINING_DATABASE_PATH)\n",
    "\n",
    "# find all csv's in the directory\n",
    "training_files = glob.glob('*.csv')\n",
    "\n",
    "# iterate through files and assign classification id\n",
    "for file in training_files:\n",
    "    if fnmatch.fnmatchcase(file, TECHNICAL_TRAINING_DATABASE_NAME_):\n",
    "        technical_training_database = pd.DataFrame.from_csv(\n",
    "            os.path.join(file),header=0, index_col=None)\n",
    "        \n",
    "        # assign classification id\n",
    "        technical_training_database['classification'] = 0\n",
    "        \n",
    "    elif fnmatch.fnmatchcase(file, NATURAL_TRAINING_DATABASE_NAME_):\n",
    "        natural_training_database = pd.DataFrame.from_csv(\n",
    "            os.path.join(file), header=0, index_col=None)\n",
    "        \n",
    "        # assign classification id\n",
    "        natural_training_database['classification'] = 1\n",
    "\n",
    "print (training_files)\n",
    "# concatenate all the data into a single file\n",
    "training_data = pd.concat([natural_training_database, \n",
    "                           technical_training_database])\n",
    "\n",
    "# remoove all the na values (other filtering done later)\n",
    "training_data = training_data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Using the API\n",
    "Before you can use the API, you have to initialize the class. We'll then work through how the data is easily filtered, stored, and used for training and prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<distinguish_nat_vs_tech.distinguish_nat_vs_tech object at 0x1071fc198>\n"
     ]
    }
   ],
   "source": [
    "# initialize class\n",
    "nat_v_tech = distinguish_nat_vs_tech()\n",
    "\n",
    "print (nat_v_tech)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25Mg    55Mn    59Co    60Ni   65Cu    66Zn    88Sr    90Zr    93Nb  \\\n",
      "0  2.6333  0.0000  0.0000  0.7809  0.000  1.6047  6.2237  0.0000  0.0000   \n",
      "1  1.5857  1.3047  0.0000  0.7762  0.000  0.0000  1.2381  0.0000  1.1667   \n",
      "2  0.0000  0.0000  0.0000  0.6381  1.719  0.0000  0.0000  1.4714  0.0000   \n",
      "3  5.3095  1.2286  0.8476  0.0000  0.000  0.0000  2.6285  0.0000  0.0000   \n",
      "4  0.0000  1.2428  0.0000  0.0000  0.000  0.6095  2.2666  0.0000  0.0000   \n",
      "\n",
      "     95Mo       ...         149Sm   153Eu   157Gd  159Tb    182W   206Pb  \\\n",
      "0  0.0000       ...        0.0000  0.0000  0.0000    0.0  0.7095  1.0524   \n",
      "1  1.3143       ...        0.0000  0.1667  0.0000    0.0  0.9571  0.5333   \n",
      "2  1.7619       ...        0.0000  0.0000  0.3476    0.0  0.1095  0.4333   \n",
      "3  0.0000       ...        1.3952  0.0000  0.0000    0.0  0.4524  1.3809   \n",
      "4  0.0000       ...        0.0000  1.0000  0.0000    0.0  0.0000  1.0714   \n",
      "\n",
      "    208Pb   232Th    238U  classification  \n",
      "0  2.3904  1.0809  0.0000               1  \n",
      "1  1.9476  0.0000  0.0095               1  \n",
      "2  0.5571  1.6238  0.2143               1  \n",
      "3  3.2762  0.1810  0.0000               1  \n",
      "4  1.3190  0.0000  0.0000               1  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# filter the data of negative values\n",
    "neg_filt_training_data = nat_v_tech.filter_negative(data=training_data)\n",
    "\n",
    "# threshold the data with a single isotope trigger\n",
    "thresh_neg_filt_training_data = nat_v_tech.apply_detection_threshold(\n",
    "                                    data=neg_filt_training_data, \n",
    "                                    threshold_value=5)\n",
    "\n",
    "# print to maake sure we're on target\n",
    "print (thresh_neg_filt_training_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25Mg    55Mn    59Co    60Ni   65Cu    66Zn    88Sr    90Zr    93Nb  \\\n",
      "0  2.6333  0.0000  0.0000  0.7809  0.000  1.6047  6.2237  0.0000  0.0000   \n",
      "1  1.5857  1.3047  0.0000  0.7762  0.000  0.0000  1.2381  0.0000  1.1667   \n",
      "2  0.0000  0.0000  0.0000  0.6381  1.719  0.0000  0.0000  1.4714  0.0000   \n",
      "3  5.3095  1.2286  0.8476  0.0000  0.000  0.0000  2.6285  0.0000  0.0000   \n",
      "4  0.0000  1.2428  0.0000  0.0000  0.000  0.6095  2.2666  0.0000  0.0000   \n",
      "\n",
      "     95Mo   ...     147Sm   149Sm   153Eu   157Gd  159Tb    182W   206Pb  \\\n",
      "0  0.0000   ...    0.0000  0.0000  0.0000  0.0000    0.0  0.7095  1.0524   \n",
      "1  1.3143   ...    1.0667  0.0000  0.1667  0.0000    0.0  0.9571  0.5333   \n",
      "2  1.7619   ...    0.0000  0.0000  0.0000  0.3476    0.0  0.1095  0.4333   \n",
      "3  0.0000   ...    0.0000  1.3952  0.0000  0.0000    0.0  0.4524  1.3809   \n",
      "4  0.0000   ...    0.0000  0.0000  1.0000  0.0000    0.0  0.0000  1.0714   \n",
      "\n",
      "    208Pb   232Th    238U  \n",
      "0  2.3904  1.0809  0.0000  \n",
      "1  1.9476  0.0000  0.0095  \n",
      "2  0.5571  1.6238  0.2143  \n",
      "3  3.2762  0.1810  0.0000  \n",
      "4  1.3190  0.0000  0.0000  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# right now training data contains the classification data. Split it. \n",
    "(training_df, target_df) = nat_v_tech.split_target_from_training_data(\n",
    "                                df=thresh_neg_filt_training_data)\n",
    "\n",
    "\n",
    "# print training data to check structure\n",
    "print (training_df.head())\n",
    "\n",
    "# print target data to check structure\n",
    "print (target_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': None, 'max_depth': 5, 'min_samples_leaf': 100, 'max_features': 'sqrt', 'loss': 'deviance', 'n_estimators': 1000, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# initialize gbc to determine max estimators with least overfitting\n",
    "GBC_INIT_PARAMS = {'loss': 'deviance', 'learning_rate': 0.1,\n",
    "\t\t\t\t   'min_samples_leaf': 100, 'n_estimators': 1000,\n",
    "\t\t\t\t   'max_depth': 5, 'random_state': None, 'max_features': 'sqrt'}\n",
    "\n",
    "# print to verify parameter init structure\n",
    "print (GBC_INIT_PARAMS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n"
     ]
    }
   ],
   "source": [
    "# find optimum boosting stages\n",
    "optimum_boosting_stages = nat_v_tech.find_min_boosting_stages(gbc_base_params=GBC_INIT_PARAMS,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  training_df=training_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  target_df=target_df)[1]\n",
    "\n",
    "# print optimum boosting stages\n",
    "print (optimum_boosting_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'random_state': [None], 'max_depth': [5], 'min_samples_leaf': [50, 100], 'n_estimators': [455], 'loss': ['exponential', 'deviance'], 'max_features': ['sqrt', 'log2'], 'learning_rate': [0.01, 0.1]}\n"
     ]
    }
   ],
   "source": [
    "# create grid search parameters in which to find the optimum set, \n",
    "# set optimum boosting stages. Note: n_estimators automatically set\n",
    "GBC_GRID_SEARCH_PARAMS = {'loss': ['exponential', 'deviance'],\n",
    "\t\t\t\t\t\t  'learning_rate': [0.01, 0.1],\n",
    "\t\t\t\t\t\t  'min_samples_leaf': [50, 100],\n",
    "\t\t\t\t\t\t  'random_state': [None],\n",
    "\t\t\t\t\t\t  'max_features': ['sqrt', 'log2'],\n",
    "\t\t\t\t\t\t  'max_depth': [5],\n",
    "\t\t\t\t\t\t  'n_estimators': [optimum_boosting_stages]}  \n",
    "\n",
    "# print search parameter grid to verify init structure\n",
    "print (GBC_GRID_SEARCH_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='exponential', max_depth=5,\n",
      "              max_features='sqrt', max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=100,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=455, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# find the optimum gbc parameters\n",
    "gbc_fitted = nat_v_tech.find_optimum_gbc_parameters(crossfolds=5,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\ttraining_df=training_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\ttarget_df=target_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tgbc_search_params=GBC_GRID_SEARCH_PARAMS)\n",
    "\n",
    "# print the optimum gbc structure\n",
    "print (gbc_fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
      "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
      "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157,\n",
      "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
      "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "       197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "       210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "       249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
      "       263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275,\n",
      "       276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288,\n",
      "       289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301,\n",
      "       302, 303, 304, 305, 306, 308, 309, 310, 311, 312, 313, 314, 315,\n",
      "       316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328,\n",
      "       329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
      "       342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
      "       355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "       368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
      "       381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
      "       394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
      "       407, 408, 409, 410, 411, 412, 413, 415, 416, 417, 418, 419, 420,\n",
      "       421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
      "       434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
      "       447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
      "       460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
      "       473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
      "       486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
      "       499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
      "       512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
      "       525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
      "       538, 539, 540, 541, 542, 543, 544, 545]),)\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   9,  10,  11,  12,  13,\n",
      "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
      "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
      "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
      "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
      "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "       105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118,\n",
      "       119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
      "       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
      "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
      "       171, 172, 173, 174, 175, 176, 178, 179, 180, 181, 182, 183, 184,\n",
      "       185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,\n",
      "       198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210,\n",
      "       211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "       224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236,\n",
      "       237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249,\n",
      "       250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262,\n",
      "       263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275,\n",
      "       276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288,\n",
      "       289, 290, 291, 292, 293, 294, 295, 296, 298, 299, 300, 301, 302,\n",
      "       303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
      "       316, 317, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
      "       330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
      "       343, 344, 345, 347, 348, 349, 351, 352, 353, 354, 355, 356, 357,\n",
      "       358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370,\n",
      "       371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383,\n",
      "       384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396,\n",
      "       397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409,\n",
      "       410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422,\n",
      "       423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
      "       436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448,\n",
      "       449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
      "       462, 463, 464, 465, 466, 467, 468, 469, 471, 472, 473, 474, 475,\n",
      "       476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488,\n",
      "       489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501,\n",
      "       502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514,\n",
      "       515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527,\n",
      "       528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540,\n",
      "       541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553,\n",
      "       554, 555, 556]),)\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
      "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
      "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
      "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
      "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
      "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
      "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "       105, 106, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119,\n",
      "       120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132,\n",
      "       133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146,\n",
      "       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n",
      "       160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172,\n",
      "       174, 175, 176, 177, 178, 179, 180, 182, 183, 184, 185, 186, 187,\n",
      "       188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n",
      "       201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213,\n",
      "       214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226,\n",
      "       227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,\n",
      "       240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252,\n",
      "       253, 254, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
      "       267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "       280, 281, 282, 283, 284, 286, 287, 288, 289, 290, 292, 293, 296,\n",
      "       297, 298, 299, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310,\n",
      "       311, 312, 313, 314, 315, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
      "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
      "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
      "       404, 405, 406, 407, 408, 409, 410, 411, 412, 414, 415, 416, 417,\n",
      "       419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431,\n",
      "       432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444,\n",
      "       445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457,\n",
      "       458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470,\n",
      "       471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483,\n",
      "       484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496,\n",
      "       497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509,\n",
      "       510, 511, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523,\n",
      "       524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536,\n",
      "       537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549,\n",
      "       550, 551, 553, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564,\n",
      "       565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577,\n",
      "       578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590,\n",
      "       591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603,\n",
      "       604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616,\n",
      "       617, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630,\n",
      "       631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643,\n",
      "       645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657,\n",
      "       658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670,\n",
      "       671, 672, 673, 674, 675, 676, 677, 678, 679, 681, 682, 683, 684,\n",
      "       685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697,\n",
      "       698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710,\n",
      "       711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723,\n",
      "       724, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737,\n",
      "       738, 739, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751,\n",
      "       752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764]),)\n",
      "(array([  1,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  15,\n",
      "        18,  19,  20,  22,  23,  24,  29,  30,  31,  32,  33,  34,  35,\n",
      "        36,  38,  40,  41,  44,  45,  46,  47,  49,  50,  51,  52,  53,\n",
      "        54,  55,  56,  57,  59,  60,  62,  64,  65,  66,  67,  69,  70,\n",
      "        71,  72,  75,  76,  77,  78,  79,  80,  81,  82,  84,  85,  86,\n",
      "        87,  89,  90,  91,  92,  93,  95,  97,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 109, 111, 112, 113, 114, 115, 117, 118, 119, 121,\n",
      "       122, 124, 125, 126, 127, 128, 131, 132, 133, 134, 135, 136, 137,\n",
      "       138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 151, 152, 154,\n",
      "       155, 156, 158, 159, 160, 161, 164, 166, 167, 168, 169, 172, 173,\n",
      "       174, 176, 177, 179, 181, 182, 183, 185, 188, 191, 193, 194, 196,\n",
      "       197, 198, 201, 203, 205, 206, 208, 209, 210, 211, 214, 215, 216,\n",
      "       217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229,\n",
      "       230, 231, 232, 233, 235, 236, 237, 239, 240, 241, 243, 244, 245,\n",
      "       246, 247, 250, 251, 252, 253, 255, 256, 257, 258, 259, 260, 262,\n",
      "       265, 266, 267, 268, 269, 270, 271, 273, 274, 275, 276, 277, 278,\n",
      "       279, 280, 281, 282, 283, 284, 289, 291, 292, 294, 295, 297, 299,\n",
      "       300, 301, 302, 303, 304, 305, 307, 309, 310, 311, 313, 314, 315,\n",
      "       316, 317, 320, 322, 326, 327, 328, 331, 333, 334, 335, 336, 338,\n",
      "       339, 340, 341, 343, 344, 346, 347, 348, 350, 352, 353, 354, 355,\n",
      "       357, 358, 359, 361, 362, 363, 364, 372, 373, 374, 375, 376, 377,\n",
      "       378, 379, 382, 383, 384, 385, 387, 388, 389, 390, 391, 392, 393,\n",
      "       394, 397, 398, 399, 402, 405, 407, 408, 409, 410, 411, 412, 413,\n",
      "       414, 416, 417, 419, 420, 422, 425, 427, 428, 429, 430, 431, 432,\n",
      "       433, 434, 436, 437, 438, 440, 441, 442, 443, 444, 445, 446, 447,\n",
      "       448, 450, 452, 453, 454, 455, 456, 457, 459, 460, 462, 463, 464,\n",
      "       465, 466, 467, 468, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
      "       479, 480, 481, 482, 484, 485, 486, 488, 490, 491, 492, 493, 494,\n",
      "       496, 497, 498, 500, 501, 502, 503, 504, 505, 506, 507, 509, 510,\n",
      "       512, 513, 514, 515, 516, 518, 519, 520, 521, 523, 524, 525, 526,\n",
      "       527, 528, 530, 531, 532, 535, 536, 537, 538, 539, 540, 541, 542,\n",
      "       543, 544, 545, 546, 547, 548, 549, 550, 551, 553, 554, 555, 557,\n",
      "       558, 559, 562, 565, 566, 569, 570, 571, 572, 573, 574, 575, 576,\n",
      "       577, 579, 580, 582, 583, 584, 585, 586, 588, 589, 590, 591, 592,\n",
      "       593, 595, 596, 599, 601, 602, 603, 604, 606, 607, 609, 610, 612,\n",
      "       615, 618, 620, 621, 622, 623, 625, 626, 627, 628, 629, 630, 631,\n",
      "       632, 633, 634, 635, 636, 640, 641, 642, 643, 645, 647, 648, 649,\n",
      "       652, 653, 654, 656, 657, 658, 659, 661, 662, 665, 666, 667, 668,\n",
      "       669, 670, 671, 672, 673, 675, 677, 680, 681, 682, 683, 684, 685,\n",
      "       687, 688, 689, 690, 691, 692, 693, 694, 695, 697, 698, 700, 701,\n",
      "       702, 703, 704, 705, 706, 708, 709, 710, 711, 712, 716, 717, 718,\n",
      "       719, 720, 721, 722, 723, 725, 726, 728, 729, 730, 731, 733, 735,\n",
      "       736, 738, 739, 742, 743, 744, 746, 747, 749, 750, 752, 753, 754,\n",
      "       756, 757, 758, 759, 761, 762, 763, 765, 766, 767, 768, 770, 771,\n",
      "       772, 774, 775, 776, 777, 779, 782, 783, 784, 786, 788, 790, 792,\n",
      "       796, 797, 799, 800, 801, 803, 805, 806, 808, 809, 810, 811, 812,\n",
      "       814, 815, 816, 817, 819, 821, 822, 824, 825, 826, 827, 830, 831,\n",
      "       832, 836, 837, 838, 839, 841, 842, 843, 844, 847, 848, 849, 850,\n",
      "       851, 852, 856, 858, 859, 860, 862, 863, 864, 865, 867, 868, 869,\n",
      "       872, 873, 874, 875, 876, 877, 881, 883, 884, 885, 886, 887, 888,\n",
      "       890, 895, 896, 897, 898, 900, 901, 904, 907, 908, 909, 911, 913,\n",
      "       914, 915, 916, 918, 919, 921, 922, 924, 925, 926, 927, 929, 930,\n",
      "       931, 932, 934, 936, 937, 938, 939, 940, 942, 943, 944, 945, 946]),)\n",
      "(array([   2,    3,    5, ..., 2895, 2896, 2897]),)\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  85,  86,  87,  88,  89,  90,  91,\n",
      "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
      "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
      "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
      "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
      "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
      "       274, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287,\n",
      "       288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300,\n",
      "       301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313,\n",
      "       314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326,\n",
      "       327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "       340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352,\n",
      "       353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,\n",
      "       366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378,\n",
      "       379, 380, 381]),)\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  11,  12,  13,\n",
      "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
      "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
      "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
      "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  66,\n",
      "        67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,\n",
      "        80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n",
      "        93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105,\n",
      "       106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118,\n",
      "       119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131,\n",
      "       132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
      "       145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157,\n",
      "       158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170,\n",
      "       171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
      "       184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
      "       197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "       210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
      "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
      "       236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248,\n",
      "       249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261,\n",
      "       262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274,\n",
      "       275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287,\n",
      "       288, 290, 291, 292, 294, 295, 296, 297, 298, 299, 300, 301, 302,\n",
      "       303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315,\n",
      "       316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328,\n",
      "       329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341,\n",
      "       342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
      "       355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "       368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
      "       381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
      "       394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406,\n",
      "       407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
      "       420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
      "       433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
      "       446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
      "       459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471,\n",
      "       472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484,\n",
      "       485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497,\n",
      "       498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510,\n",
      "       511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523,\n",
      "       524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536,\n",
      "       537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549,\n",
      "       550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562,\n",
      "       563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575,\n",
      "       576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588,\n",
      "       589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601,\n",
      "       602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614,\n",
      "       615, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628,\n",
      "       629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641,\n",
      "       642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654,\n",
      "       655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667,\n",
      "       668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680,\n",
      "       681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693,\n",
      "       694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706,\n",
      "       707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 718, 719, 720,\n",
      "       721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733,\n",
      "       734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746,\n",
      "       747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759,\n",
      "       760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772,\n",
      "       773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785,\n",
      "       786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798,\n",
      "       799, 800, 801, 802, 803, 804, 806, 807, 808, 809, 810, 811, 812,\n",
      "       813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825,\n",
      "       826, 827, 828, 829, 830, 831]),)\n",
      "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  98,  99, 100, 101, 102, 103, 104,\n",
      "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
      "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
      "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
      "       144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n",
      "       157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n",
      "       170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
      "       183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "       196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n",
      "       209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n",
      "       222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n",
      "       235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n",
      "       248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n",
      "       261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n",
      "       274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n",
      "       287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n",
      "       300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
      "       313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "       326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
      "       339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
      "       352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
      "       365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
      "       378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
      "       391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n",
      "       404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n",
      "       417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n",
      "       430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n",
      "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
      "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
      "       469, 470, 471, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482,\n",
      "       483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495,\n",
      "       496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508,\n",
      "       509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521,\n",
      "       522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534,\n",
      "       535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547,\n",
      "       548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560,\n",
      "       561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573,\n",
      "       574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586,\n",
      "       587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599,\n",
      "       600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612,\n",
      "       613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625,\n",
      "       626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638,\n",
      "       639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651,\n",
      "       652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664,\n",
      "       665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677,\n",
      "       678, 679, 680, 681, 682]),)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/tron/Praetorius_Goldberg_2016/examples/output/data_summaries/summary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-b4a95f862568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                                                 \u001b[0misotope_trigger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'140Ce'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                                                 \u001b[0mgbc_fitted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbc_fitted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \t\t\t\t\t\t\t\t\t\tX=X, y=y)\n\u001b[0m",
      "\u001b[0;32m/Users/tron/Praetorius_Goldberg_2016/distinguish_nat_vs_tech.py\u001b[0m in \u001b[0;36mapply_trained_classification\u001b[0;34m(self, test_data_path, output_summary_data_path, output_summary_base_name, gbc_fitted, track_class_probabilities, isotope_trigger, X, y, filter_neg, apply_threshold, critical_isotopes, track_particle_counts)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \t\tX_test_data_track.to_csv(os.path.join(output_summary_data_path, 'data_summaries',\n\u001b[0;32m--> 222\u001b[0;31m \t\t\t\t\t\t\t\t\t\t\t  output_summary_base_name), index=False)\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1458\u001b[0m             f = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1459\u001b[0m                             \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m                             compression=self.compression)\n\u001b[0m\u001b[1;32m   1461\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path, mode, encoding, compression, memory_map)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/tron/Praetorius_Goldberg_2016/examples/output/data_summaries/summary.csv'"
     ]
    }
   ],
   "source": [
    "# conform the test data for ML and store it as X and y.\n",
    "(X, y) = nat_v_tech.conform_data_for_ML(training_df=training_df, target_df=target_df)\n",
    "\n",
    "# use the X and y data to train the model. Then test the trained model against the test data and output results.\n",
    "nat_v_tech.apply_trained_classification(test_data_path=IMPORT_TESTING_DATABASE_PATH,\n",
    "\t\t\t\t\t\t\t\t\t\toutput_summary_data_path=OUTPUT_DATA_SUMMARY_PATH,\n",
    "\t\t\t\t\t\t\t\t\t\toutput_summary_base_name='summary.csv',\n",
    "\t\t\t\t\t\t\t\t\t\ttrack_class_probabilities=[0.1, 0.1],\n",
    "\t\t\t\t\t\t\t\t\t\tisotope_trigger='140Ce',\n",
    "\t\t\t\t\t\t\t\t\t\tgbc_fitted=gbc_fitted,\n",
    "\t\t\t\t\t\t\t\t\t\tX=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
